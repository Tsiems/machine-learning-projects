{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning Classification of Play Type in NFL Play-By-Play Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ian Johnson, Derek Phanekham, Travis Siems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NFL (National Football League) has 32 teams split into two conferences, the AFC and NFC. Each of the 32 teams plays 16 games during the regular season (non-playoff season) every year. Due to the considerable viewership of American football, as well as the pervasiveness of fantasy football, considerable data about the game is collected. During the 2015-2016 season, information about every play from each game that occurred was logged. All of that data was consolidated into a single data set which is analyzed throughout this report.\n",
    "\n",
    "In this report, we will attempt to classify the type of a play, given the game situation before the play began. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Classification Task\n",
    "\n",
    "We will attempt to classify plays based on play type using information about the state of the game prior to the start of the play. This is expected to be an exceptionally difficult classification task, due to the amount of noise in the dataset (specifically, the decision to run vs pass the ball is often a seemingly random one). A successful classifier would have huge value to defensive coordinators, who could call plays based on the expected offensive playcall. Because it may be very difficult to identify what play will be called, it is relevant to provide a probability of a given playcall in a situation. For example, it would be useful to provide the probability of a 4th down conversion attempt, even if the overall prediction is that a punt occurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "In order to prepare the data for classification, a number of variables from the original dataset will be removed, as they measure the result of the play, not the state of the game prior to the start of the play. The dataset being included in this report has had previous cleaning and preprocessing performed in our previous report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38600 entries, 0 to 42875\n",
      "Data columns (total 13 columns):\n",
      "Drive            38600 non-null int64\n",
      "qtr              38600 non-null int64\n",
      "down             38600 non-null int64\n",
      "TimeSecs         38600 non-null float64\n",
      "yrdline100       38600 non-null float64\n",
      "ydstogo          38600 non-null float64\n",
      "ydsnet           38600 non-null float64\n",
      "GoalToGo         38600 non-null int64\n",
      "posteam          38600 non-null object\n",
      "DefensiveTeam    38600 non-null object\n",
      "PosTeamScore     38600 non-null float64\n",
      "ScoreDiff        38600 non-null float64\n",
      "PlayType         38600 non-null object\n",
      "dtypes: float64(6), int64(4), object(3)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#For final version of report, remove warnings for aesthetics.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Libraries used for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('data/cleaned.csv') # read in the csv file\n",
    "\n",
    "\n",
    "\n",
    "colsToInclude = [ 'Drive', 'qtr', 'down',\n",
    "                 'TimeSecs', 'yrdline100','ydstogo','ydsnet',\n",
    "                 'GoalToGo','posteam','DefensiveTeam',\n",
    "                 'PosTeamScore','ScoreDiff', 'PlayType']\n",
    "\n",
    "df = df[colsToInclude]\n",
    "df = df[[p not in [\"Sack\", \"No Play\", \"QB Kneel\", \"Spike\"] for p in df.PlayType]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Embeddings\n",
    "\n",
    "We will use neural network embeddings from TensorFlow for the posteam and DefensiveTeam. However, we will be building these embeddings manually using one-hot encoding and additional fully-connected layers in each of the deep architectures. The following Python function was used for one-hot encoding, and was adapted from the website referenced in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#Simple function for 1 hot encoding\n",
    "def encode_onehot(df, cols):\n",
    "    \"\"\"\n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.\n",
    "    \n",
    "    Modified from: https://gist.github.com/kljensen/5452382\n",
    "    \n",
    "    Details:\n",
    "    \n",
    "    http://en.wikipedia.org/wiki/One-hot\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    \n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(outtype='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df\n",
    "\n",
    "df = encode_onehot(df, cols=['posteam', 'DefensiveTeam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are descriptions of the remaining data columns in the play-by-play dataset. Note that the one-hot encoded columns do not follow the structure listed below, but for the sake of readability they are presented as if they were not one-hot encoded.\n",
    "\n",
    "* **GameID** (*nominal*): A unique integer which identifies each game played \n",
    "* **Drive** (*ordinal*): The number of the drive during a game when the play occurred (indexed at one, so the first drive of the game has Drive 1 and the nth drive has Drive n)\n",
    "* **qtr** (*interval*): The quarter of the game when the play occurred\n",
    "* **down** (*interval*): The down when the play occurred (1st, 2nd, 3rd, or 4th)\n",
    "* **TimeSecs** (*interval*): The remaining game time, in seconds, when the play began\n",
    "* **yrdline100** (*ratio*): The absolute yard-line on the field where the play started (from 0 to 100, where 0 is the defensive end zone and 100 is the offensive end zone of the team with the ball)\n",
    "* **ydstogo** (*ratio*): The number of yards from the line of scrimmage to the first-down line\n",
    "* **ydsnet** (*ratio*): The number of yards from the beginning of the drive to the current line of scrimmage\n",
    "* **GoalToGo** (*nominal*): A binary attribute whose value is 1 if there is no first down line (the end-zone is the first down line) or 0 if there is a normal first down line\n",
    "* **posteam** (*nominal*): A 2-or-3 character code representing the team on offense\n",
    "* **PosTeamScore** (*ratio*): The score of the team with possesion of the ball\n",
    "* **DefensiveTeam** (*nominal*): A 2-or-3 character code representing the team on defense\n",
    "* **ScoreDiff**: (*ratio*) The difference in score between the offensive and defensive at the time of the play.\n",
    "* **PlayType**: (*nominal*) An attribute that identifies the type of play (i.e. Kickoff, Run, Pass, Sack, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "\n",
    "The value of a classifier will be evaulated using the following cost matrix. Costs in the matrix which are set to 1 represent play predictions that would never actually occur in the context of a football game. For example, if we predicted a pass play and a kickoff occurs, then the classifier has a significant flaw. \n",
    "\n",
    "Bolded weights represent actual mispredictions that could occur.\n",
    "\n",
    "|                | Actual Play | Pass | Run | Kickoff |     Punt    | Extra Point | Field Goal | Onside Kick |\n",
    "|----------------|-------------|------|-----|---------|-------------|------------|-------------|-------------|\n",
    "| Predicted Play |             |      |     |         |             |            |             | |\n",
    "| Pass           |             | 0    | **0.1** | 1       | **0.15** | **0.15**        | **0.1**         | 1           |  \n",
    "| Run            |             | **0.1**  | 0   | 1       | **0.15** | **0.15**        | **0.1**         | 1           | \n",
    "| Kickoff        |             | 1    | 1   | 0     |  1  | 1           | 1          | **0.75**       |\n",
    "| Punt           |             | **0.25**    | **0.25**   | 1   | 0 |1       |  **0.15**           | 1           |\n",
    "| Extra Point    |             | **0.4**  | **0.4** | 1       | 1 | 0           | 1          | 1           |\n",
    "| Field Goal     |             | **0.4** | **0.4** | 1       | **0.1** | 1           | 0          | 1           |\n",
    "| Onside Kick    |             | 1    | 1   | **0.25**    |  1 |1           | 1          | 0           |\n",
    "\n",
    "\n",
    "This performance metric is the best for this classification problem because the actual potential cost of an incorrect play prediction varies significantly based on the nature of the misclassification. In an actual football game, it would be very costly to predict an extra point and have the opposing team run a pass play. This means that they ran a fake extra point and went for a two-point conversion. However, if a pass play is predicted and a run play occurs, the cost of the error is minimal because the defensive strategy for defending against run and pass plays.\n",
    "\n",
    "Because the goal of this classification is to help inform defensive play-calling, a cost matrix is helpful because it allows a defensive coordinator to set his own costs to produce his own classifier, without any knowledge of the actualy computation that occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Methodology\n",
    "\n",
    "We will use a stratified 10-fold cross validation technique to compare the models. We use a sequential partition of the data because this mirrors how data will be collected and analyzed. For our use, we assume that it is okay to use data in the “future” to predict data “now” because it can represent data from a previous football season. For example, if we use the first 90% of data for training and the remaining 10% of data for testing, that would simulate using most of the current season's data to predict plays towards the end of this season. If we use the first 50% and last 40% of data for training and the remaining 10% for testing, this would simulate using 40% of the previous season's data and the first 50% of this season's data to predict plays happening around the middle of the current season. \n",
    "\n",
    "By using stratification, we can use a more representative sample of the distribution of play types. This stratified sample will reduce variance in the estimation. Given that the dataset only covers play-by-play data for one football season and using our assumptions, we can conclude that the stratified 10-fold cross validation technique will give us an ideal comparison between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "#Using a 10-fold stratified shuffle split.\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "y,levels = pd.factorize(df.PlayType.values)\n",
    "X = df.drop('PlayType', 1).values.astype(np.float32)\n",
    "\n",
    "\n",
    "num_classes = len(levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Before we build any models, we define a cost function in Python below, which is used to test all of our forthcoming models. It computes the item-wise product of a confusion matrix and our cost matrix, and returns the sum of all of the elements in the resulting matrix. We also define a function to calculate area under roc curve for a multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "cost_mat =     [[0  ,.1  , 1   , .15 , 0.15, .1 , 1   ],\n",
    "                [.1 , 0  , 1   , 0.15, 0.15, 0.1, 1   ],\n",
    "                [1  , 1  , 0   , 1   , 1   , 1  , 0.75],\n",
    "                [.25,0.25, 1   , 0   , 1   ,0.15,  1  ],\n",
    "                [0.4, 0.4, 1   , 1   , 0   , 1  ,  1  ],\n",
    "                [0.4, 0.4, 1   , 0.1 , 1   , 0  ,  1  ],\n",
    "                [1  , 1  , 0.25, 1   , 1   , 1  ,  0  ]]\n",
    "\n",
    "def cost(Y, yhat):\n",
    "    return np.sum(np.multiply(confusion_matrix(Y,yhat), cost_mat))\n",
    "\n",
    "def auc_of_roc(Y,yhat):\n",
    "    classes = ['Pass', 'Run', 'Kickoff', 'Punt', 'Extra Point', 'Field Goal', 'Onside Kick']\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    for c in classes:\n",
    "        tempY = [x==c for x in Y]\n",
    "        tempYhat = [x==c for x in yhat]\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(tempY, tempYhat)\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=c+' (area = %0.2f)' % (roc_auc))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='Luck')\n",
    "\n",
    "    mean_tpr /= len(classes)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    print(mean_auc)\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_auc\n",
    "\n",
    "auc_roc_scorer = make_scorer(auc_of_roc)\n",
    "scorer = make_scorer(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Accessory Plotting Function\n",
    "\n",
    "The following plotting function will be used for tuning hyperparameters for various algorithms.\n",
    "It is adapted from one of the instructional ML notebooks for CSE 5393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adapted From MachineLearningNotebooks/09_Evaluation\n",
    "#Credit: Dr. Eric Larson\n",
    "def plot_filled(train_scores,test_scores,train_x_axis, xlabel=''):\n",
    "\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_x_axis, test_mean,\n",
    "             color='blue', marker='o',\n",
    "             markersize=5, label='testing cost')\n",
    "\n",
    "    plt.fill_between(train_x_axis,\n",
    "                     test_mean + test_std,\n",
    "                     test_mean - test_std,\n",
    "                     alpha=0.15, color='blue')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('Cost')\n",
    "    plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Deep Learning Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq_bbr2te\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpce5voe6j\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmqrcxh1h\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpywst8vrx\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1546.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpgvy4kbai\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpa3ebduat\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpuuhl_yb_\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_v_1cm2x\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfkkza14q\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpb4833vky\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1903.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphxc16s5h\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664.4\n",
      "1882.05\n",
      "scores\n",
      "[1643.0999999999999, 1546.05, 1623.25, 1726.8999999999999, 1632.3499999999999, 1580.3500000000001, 1484.3499999999999, 1903.3499999999999, 1664.4000000000001, 1882.05]\n",
      "CPU times: user 2min 52s, sys: 7.2 s, total: 2min 59s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def deep_model(X, y):\n",
    "\n",
    "    \n",
    "    #Embeddings layer\n",
    "    teamembeddings = layers.stack(X[:,11:75], layers.fully_connected, [20,4])\n",
    "    teamembeddings = tf.nn.relu(teamembeddings)\n",
    "    \n",
    "    #Non-embeddings features\n",
    "    otherfeatures = X[:,0:10]\n",
    "\n",
    "    #Concatenate the embeddings with the non-embeddings\n",
    "    tensors = tf.concat(1, [teamembeddings, otherfeatures])\n",
    "\n",
    "    tensors = layers.stack(tensors, layers.fully_connected, [100,50,25, 100])\n",
    "    \n",
    "    #try different activation functions sigmoid\n",
    "    tensors = tf.nn.relu(tensors)\n",
    "\n",
    "    pred, loss = learn.models.logistic_regression(tensors, y)\n",
    "    \n",
    "    return pred, loss\n",
    "\n",
    "def tmp(X,y):\n",
    "    \n",
    "    return learn.models.logistic_regression(X, y)\n",
    "    \n",
    "\n",
    "classifier = learn.TensorFlowEstimator(model_fn=deep_model, \n",
    "                                       n_classes=7, batch_size=50,\n",
    "                                       steps=10000, learning_rate=0.005)\n",
    "\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    classifier = learn.TensorFlowEstimator(model_fn=deep_model, \n",
    "                                       n_classes=7, batch_size=500,\n",
    "                                       steps=1000, learning_rate=0.05)\n",
    "    classifier.fit(X[train_index], y[train_index])\n",
    "    yhat = classifier.predict(X[test_index])\n",
    "\n",
    "    print(cost(y[test_index], yhat))\n",
    "    scores.append(cost(y[test_index], yhat))\n",
    "\n",
    "print(\"scores\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,  -1.00000000e+00,\n",
       "         3.60000000e+03,   3.50000000e+01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Deep Learning Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under Multiclass ROC Curve Difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         3.56100000e+03,   6.20000000e+01,   1.00000000e+01,\n",
       "         3.10000000e+01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Drive', 'qtr', 'down', 'TimeSecs', 'yrdline100', 'ydstogo', 'ydsnet',\n",
       "       'GoalToGo', 'PosTeamScore', 'ScoreDiff', 'PlayType',\n",
       "       'DefensiveTeam=ARI', 'DefensiveTeam=ATL', 'DefensiveTeam=BAL',\n",
       "       'DefensiveTeam=BUF', 'DefensiveTeam=CAR', 'DefensiveTeam=CHI',\n",
       "       'DefensiveTeam=CIN', 'DefensiveTeam=CLE', 'DefensiveTeam=DAL',\n",
       "       'DefensiveTeam=DEN', 'DefensiveTeam=DET', 'DefensiveTeam=GB',\n",
       "       'DefensiveTeam=HOU', 'DefensiveTeam=IND', 'DefensiveTeam=JAC',\n",
       "       'DefensiveTeam=KC', 'DefensiveTeam=MIA', 'DefensiveTeam=MIN',\n",
       "       'DefensiveTeam=NE', 'DefensiveTeam=NO', 'DefensiveTeam=NYG',\n",
       "       'DefensiveTeam=NYJ', 'DefensiveTeam=OAK', 'DefensiveTeam=PHI',\n",
       "       'DefensiveTeam=PIT', 'DefensiveTeam=SD', 'DefensiveTeam=SEA',\n",
       "       'DefensiveTeam=SF', 'DefensiveTeam=STL', 'DefensiveTeam=TB',\n",
       "       'DefensiveTeam=TEN', 'DefensiveTeam=WAS', 'posteam=ARI', 'posteam=ATL',\n",
       "       'posteam=BAL', 'posteam=BUF', 'posteam=CAR', 'posteam=CHI',\n",
       "       'posteam=CIN', 'posteam=CLE', 'posteam=DAL', 'posteam=DEN',\n",
       "       'posteam=DET', 'posteam=GB', 'posteam=HOU', 'posteam=IND',\n",
       "       'posteam=JAC', 'posteam=KC', 'posteam=MIA', 'posteam=MIN', 'posteam=NE',\n",
       "       'posteam=NO', 'posteam=NYG', 'posteam=NYJ', 'posteam=OAK',\n",
       "       'posteam=PHI', 'posteam=PIT', 'posteam=SD', 'posteam=SEA', 'posteam=SF',\n",
       "       'posteam=STL', 'posteam=TB', 'posteam=TEN', 'posteam=WAS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38600, 62)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,12:75].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>yrdline100</th>\n",
       "      <th>ydstogo</th>\n",
       "      <th>ydsnet</th>\n",
       "      <th>GoalToGo</th>\n",
       "      <th>PosTeamScore</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>...</th>\n",
       "      <th>posteam=OAK</th>\n",
       "      <th>posteam=PHI</th>\n",
       "      <th>posteam=PIT</th>\n",
       "      <th>posteam=SD</th>\n",
       "      <th>posteam=SEA</th>\n",
       "      <th>posteam=SF</th>\n",
       "      <th>posteam=STL</th>\n",
       "      <th>posteam=TB</th>\n",
       "      <th>posteam=TEN</th>\n",
       "      <th>posteam=WAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3561.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3506.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drive  qtr  down  TimeSecs  yrdline100  ydstogo  ydsnet  GoalToGo  \\\n",
       "0      1    1    -1    3600.0        35.0      0.0     0.0         0   \n",
       "1      1    1     1    3600.0        80.0     10.0    18.0         0   \n",
       "2      1    1     1    3561.0        62.0     10.0    31.0         0   \n",
       "3      1    1     2    3544.0        53.0      1.0    31.0         0   \n",
       "4      1    1     1    3506.0        49.0     10.0    45.0         0   \n",
       "\n",
       "   PosTeamScore  ScoreDiff     ...      posteam=OAK  posteam=PHI  posteam=PIT  \\\n",
       "0           0.0        0.0     ...              0.0          0.0          1.0   \n",
       "1           0.0        0.0     ...              0.0          0.0          1.0   \n",
       "2           0.0        0.0     ...              0.0          0.0          1.0   \n",
       "3           0.0        0.0     ...              0.0          0.0          1.0   \n",
       "4           0.0        0.0     ...              0.0          0.0          1.0   \n",
       "\n",
       "   posteam=SD  posteam=SEA  posteam=SF  posteam=STL  posteam=TB  posteam=TEN  \\\n",
       "0         0.0          0.0         0.0          0.0         0.0          0.0   \n",
       "1         0.0          0.0         0.0          0.0         0.0          0.0   \n",
       "2         0.0          0.0         0.0          0.0         0.0          0.0   \n",
       "3         0.0          0.0         0.0          0.0         0.0          0.0   \n",
       "4         0.0          0.0         0.0          0.0         0.0          0.0   \n",
       "\n",
       "   posteam=WAS  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2cd6ee2c70b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[sum(yhat == x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape\n",
    "#3,860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[10]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(X, y):\n",
    "    print(X[train_index,].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('PlayType', 1).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.drop('PlayType', 1).values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
