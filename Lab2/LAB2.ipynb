{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Play Type in NFL Play-By-Play Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ian Johnson, Derek Phanekham, Travis Siems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NFL (National Football League) has 32 teams split into two conferences, the AFC and NFC. Each of the 32 teams plays 16 games during the regular season (non-playoff season) every year. Due to the considerable viewership of American football, as well as the pervasiveness of fantasy football, considerable data about the game is collected. During the 2015-2016 season, information about every play from each game that occurred was logged. All of that data was consolidated into a single data set which is analyzed throughout this report.\n",
    "\n",
    "In this report, we will attempt to classify the play type of a play, given the game situation before the play began. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Classification Task\n",
    "\n",
    "We will attempt to classify plays based on play type using information about the state of the game prior to the start of the play. This is expected to be an exceptionally difficult classification task, due to the amount of noise in the dataset (specifically, the decision to run vs pass the ball is often a seemingly random one). A successful classifier would have huge value to defensive coordinators, who could call plays based on the expected offensive playcall. Because it may be very difficult to identify what play will be called, it is relevant to provide a probability of a given playcall in a situation. For example, it would be useful to provide the probability of a 4th down conversion attempt, even if the overall prediction is that a punt occurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "In order to prepare the data for classification, a number of variables from the original dataset will be removed, as they measure the result of the play, not the state of the game prior to the start of the play. The dataset being included in this report has had previous cleaning and preprocessing performed in our previous report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38600 entries, 0 to 42875\n",
      "Data columns (total 14 columns):\n",
      "GameID           38600 non-null int64\n",
      "Drive            38600 non-null int64\n",
      "qtr              38600 non-null int64\n",
      "down             38600 non-null int64\n",
      "TimeSecs         38600 non-null float64\n",
      "yrdline100       38600 non-null float64\n",
      "ydstogo          38600 non-null float64\n",
      "ydsnet           38600 non-null float64\n",
      "GoalToGo         38600 non-null int64\n",
      "posteam          38600 non-null object\n",
      "DefensiveTeam    38600 non-null object\n",
      "PosTeamScore     38600 non-null float64\n",
      "ScoreDiff        38600 non-null float64\n",
      "PlayType         38600 non-null object\n",
      "dtypes: float64(6), int64(5), object(3)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#For final version of report, remove warnings for aesthetics.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Libraries used for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('data/cleaned.csv') # read in the csv file\n",
    "\n",
    "colsToInclude = ['GameID', 'Drive', 'qtr', 'down',\n",
    "                 'TimeSecs', 'yrdline100','ydstogo','ydsnet',\n",
    "                 'GoalToGo','posteam','DefensiveTeam',\n",
    "                 'PosTeamScore','ScoreDiff', 'PlayType']\n",
    "\n",
    "df = df[colsToInclude]\n",
    "df = df[[p not in [\"Sack\", \"No Play\", \"QB Kneel\", \"Spike\"] for p in df.PlayType]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of attributes will be one-hot encoded, as they are categorical variables which won't work with our classification algorithm. The following Python function was used for one-hot encoding, and was adapted from the website referenced in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#Simple function for 1 hot encoding\n",
    "def encode_onehot(df, cols):\n",
    "    \"\"\"\n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.\n",
    "    \n",
    "    Modified from: https://gist.github.com/kljensen/5452382\n",
    "    \n",
    "    Details:\n",
    "    \n",
    "    http://en.wikipedia.org/wiki/One-hot\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    \n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(outtype='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df\n",
    "\n",
    "df = encode_onehot(df, cols=['posteam', 'DefensiveTeam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are descriptions of the remaining data columns in the play-by-play dataset. Note that the one-hot encoded columns do not follow the structure listed below, but for the sake of readability they are presented as if they were not one-hot encoded.\n",
    "\n",
    "* **GameID** (*nominal*): A unique integer which identifies each game played \n",
    "* **Drive** (*ordinal*): The number of the drive during a game when the play occurred (indexed at one, so the first drive of the game has Drive 1 and the nth drive has Drive n)\n",
    "* **qtr** (*interval*): The quarter of the game when the play occurred\n",
    "* **down** (*interval*): The down when the play occurred (1st, 2nd, 3rd, or 4th)\n",
    "* **TimeSecs** (*interval*): The remaining game time, in seconds, when the play began\n",
    "* **yrdline100** (*ratio*): The absolute yard-line on the field where the play started (from 0 to 100, where 0 is the defensive end zone and 100 is the offensive end zone of the team with the ball)\n",
    "* **ydstogo** (*ratio*): The number of yards from the line of scrimmage to the first-down line\n",
    "* **ydsnet** (*ratio*): The number of yards from the beginning of the drive to the current line of scrimmage\n",
    "* **GoalToGo** (*nominal*): A binary attribute whose value is 1 if there is no first down line (the end-zone is the first down line) or 0 if there is a normal first down line\n",
    "* **posteam** (*nominal*): A 2-or-3 character code representing the team on offense\n",
    "* **PosTeamScore** (*ratio*): The score of the team with possesion of the ball\n",
    "* **DefensiveTeam** (*nominal*): A 2-or-3 character code representing the team on defense\n",
    "* **ScoreDiff**: (*ratio*) The difference in score between the offensive and defensive at the time of the play.\n",
    "* **PlayType**: (*nominal*) An attribute that identifies the type of play (i.e. Kickoff, Run, Pass, Sack, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "\n",
    "The value of a classifier will be evaulated using the following cost matrix. Costs in the matrix which are set to 1 represent play predictions that would never actually occur in the context of a football game. For example, if we predicted a pass play and a kickoff occurs, then the classifier has a significant flaw. \n",
    "\n",
    "Bolded weights represent actual mispredictions that could occur.\n",
    "\n",
    "|                | Actual Play | Pass | Run | Kickoff | Extra Point | Field Goal | Onside Kick |     Punt    |\n",
    "|----------------|-------------|------|-----|---------|-------------|------------|-------------|-------------|\n",
    "| Predicted Play |             |      |     |         |             |            |             | |\n",
    "| Pass           |             | 0    | **0.1** | 1       | **0.15**        | **0.1**         | 1           |  **0.15** |\n",
    "| Run            |             | **0.1**  | 0   | 1       | **0.15**        | **0.1**         | 1           | **0.15** |\n",
    "| Kickoff        |             | 1    | 1   | 0       | 1           | 1          | **0.75**       | 1 |\n",
    "| Extra Point    |             | **0.4**  | **0.4** | 1       | 0           | 1          | 1           | 1 |\n",
    "| Field Goal     |             | **0.4** | **0.4** | 1       | 1           | 0          | 1           | **0.1** |\n",
    "| Onside Kick    |             | 1    | 1   | **0.25**    | 1           | 1          | 0           | 1 |\n",
    "| Punt           |             | **0.25**    | **0.25**   | 1   |1       |  **0.15**           | 1           | 0 |\n",
    "\n",
    "This performance metric is the best for this classification problem because the actual potential cost of an incorrect play prediction varies significantly based on the nature of the misclassification. In an actual football game, it would be very costly to predict an extra point and have the opposing team run a pass play. This means that they ran a fake extra point and went for a two-point conversion. However, if a pass play is predicted and a run play occurs, the cost of the error is minimal because the defensive strategy for defending against run and pass plays.\n",
    "\n",
    "Because the goal of this classification is to help inform defensive play-calling, a cost matrix is helpful because it allows a defensive coordinator to set his own costs to produce his own classifier, without any knowledge of the actualy computation that occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Before we build any models, we define a cost function in Python below, which is used to test all of our forthcoming models. It computes the item-wise product of a confusion matrix and our cost matrix, and returns the sum of all of the elements in the resulting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cost(Y, yhat):\n",
    "    \n",
    "    cost_mat = [[0  ,.1  , 1   , .15 , .1 , 1   , 0.15],\n",
    "                [.1 , 0  , 1   , 0.15, 0.1, 1   , 0.15],\n",
    "                [1  , 1  , 0   , 1   , 1  , 0.75, 1   ],\n",
    "                [0.4, 0.4, 1   , 0   , 1  ,  1  , 1   ],\n",
    "                [0.4, 0.4, 1   , 1   , 0  ,  1  , 0.1 ],\n",
    "                [1  , 1  , 0.25, 1   , 1  ,  0  , 1   ],\n",
    "                [.25,0.25, 1   , 1   ,0.15,  1  , 0   ]]\n",
    "    \n",
    "    return np.sum(np.multiply(confusion_matrix(Y,yhat), cost_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.300000000000004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = df[1:1000]\n",
    "\n",
    "Y = df.PlayType.values\n",
    "\n",
    "X = df.drop('PlayType', 1).values\n",
    "\n",
    "#TODO: mess with these \n",
    "clf = LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "\n",
    "clf.fit(X, Y)\n",
    "\n",
    "yhat = clf.predict(X)\n",
    "\n",
    "cost(Y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1., ...,  -1.,   0.,   0.],\n",
       "       [  1.,   1.,   1., ...,  -1.,   0.,   0.],\n",
       "       [  1.,   1.,   2., ...,  -1.,   0.,   0.],\n",
       "       ..., \n",
       "       [ 22.,   4.,   2., ...,  -1.,   0.,   0.],\n",
       "       [ 22.,   4.,   3., ...,  -1.,   0.,   0.],\n",
       "       [ 22.,   4.,   4., ...,  -1.,   0.,   0.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=1e-06,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy is  0.681972951472\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
